# Learning Spark
### chapter1. 아파치 스파크 소개: 통합 분석 엔진

아파치 스파크란 무엇인가?
- 데이터 센터나 클라우드에서 대규모 분산 데이터 처리를 하기 위해 설계된 통합형 엔진이다.
- 중간 연산을 위해 메모리 저장소를 지원하여 기존 하둡 맵리듀스보다 훨씬 빠르게 동작한다.
- 머신러닝, 대화형 질의를 위한 SQL, 실시간 데이터 처리를 위한 스트리밍 처리, 그래프 처리 등을 쉽게 사용 가능한 API들로 이루어진 라이브러리를 가지고 있다.

**핵심 특성**
1. 속도
    질의 연산을 방향성 비순환 그래프(DAG)로 구성한다. 이 DAG의 스케줄러와 최적화 모듈이 효율적인 연산 그래프를 만들어 태스크로 분해한다. 이를 통해 클러스터의 워커 노드 위에서 병렬 수행될 수 있다.
    물리적 실행 엔진 텅스텐이 전체적 코드 생성 기법을 써서 실행을 위한 최대한 간결한 코드를 생성해낸다.
    모든 중간 결과가 메모리에 유지되기 때문에 디스크 I/O를 적게 사용하여 성능이 크게 향상된다.
2. 사용 편리성
    데이터 프레임이나 데이터세트 같은 고수준 데이터 추상화 계층 아래에 유연하고 단순한 분산 데이터 세트(RDD)라는 자료구조를 구축하여 단순성을 실현했다.
    연산의 종류로 트랜스포메이션(transformaion)과 액션(action)의 집합이 단순한 프로그래밍 모델을 제공한다.
3. 모듈성
    문서화가 잘된 API들로 이루어진 통합 라이브러리를 제공하며, 스파크 SQL, 스파크 정형화 스트리밍, 스파크 MLLlib, GraphX 등의 컴포넌트를 하나의 엔진 안에서 연동된 상태로 사용할 수 있다. 한마디로 스파크를 쓴다면 자신의 워크로드를 모두 커버하는 하나의 처리 엔진을 사용한다고 말할 수 있다.
4. 확장성
    스파크는 저장보다는 빠른 병렬 연산 엔진이 중심이 된다. 하둡은 저장과 연산을 모두 포함하지만 스파크는 이를 분리했기에 다양한 수많은 데이터 소스에서 데이터를 읽고 처리할 수 있다는 것을 의미한다. 


**컴포넌트**

![img](https://velog.velcdn.com/images/busybean3/post/741382af-6746-4843-9002-7459c5d035dd/image.png)
위 그림에서 보듯,  4개의 다양한 워크로드를 위한 라이브러리로 스파크 SQL, 스파크 MLlib, 스파크 정형과 스트리밍, GraphX 등을 제공한다. API를 써서 스파크 애플리케이션을 만들면 스파크 코어 엔진이 적절한 DAG로 변환해 실행한다. 스파크 코어는 자바, R, 스칼라, SQL, 파이썬 중  어느 것으로 사용하더라도 실제 코드는 경량화된 바이트 코드로 변환되어 워커 노드의 JVM에서 실행된다.

