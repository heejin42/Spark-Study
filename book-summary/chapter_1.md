# Learning Spark
## chapter1. 아파치 스파크 소개: 통합 분석 엔진

### 아파치 스파크란 무엇인가?
- 데이터 센터나 클라우드에서 대규모 분산 데이터 처리를 하기 위해 설계된 통합형 엔진이다.
- 중간 연산을 위해 메모리 저장소를 지원하여 기존 하둡 맵리듀스보다 훨씬 빠르게 동작한다.
- 머신러닝, 대화형 질의를 위한 SQL, 실시간 데이터 처리를 위한 스트리밍 처리, 그래프 처리 등을 쉽게 사용 가능한 API들로 이루어진 라이브러리를 가지고 있다.

**핵심 특성**
1. 속도
    질의 연산을 방향성 비순환 그래프(DAG)로 구성한다. 이 DAG의 스케줄러와 최적화 모듈이 효율적인 연산 그래프를 만들어 태스크로 분해한다. 이를 통해 클러스터의 워커 노드 위에서 병렬 수행될 수 있다.
    물리적 실행 엔진 텅스텐이 전체적 코드 생성 기법을 써서 실행을 위한 최대한 간결한 코드를 생성해낸다.
    모든 중간 결과가 메모리에 유지되기 때문에 디스크 I/O를 적게 사용하여 성능이 크게 향상된다.
2. 사용 편리성
    데이터 프레임이나 데이터세트 같은 고수준 데이터 추상화 계층 아래에 유연하고 단순한 분산 데이터 세트(RDD)라는 자료구조를 구축하여 단순성을 실현했다.
    연산의 종류로 트랜스포메이션(transformaion)과 액션(action)의 집합이 단순한 프로그래밍 모델을 제공한다.
3. 모듈성
    문서화가 잘된 API들로 이루어진 통합 라이브러리를 제공하며, 스파크 SQL, 스파크 정형화 스트리밍, 스파크 MLLlib, GraphX 등의 컴포넌트를 하나의 엔진 안에서 연동된 상태로 사용할 수 있다. 한마디로 스파크를 쓴다면 자신의 워크로드를 모두 커버하는 하나의 처리 엔진을 사용한다고 말할 수 있다.
4. 확장성
    스파크는 저장보다는 빠른 병렬 연산 엔진이 중심이 된다. 하둡은 저장과 연산을 모두 포함하지만 스파크는 이를 분리했기에 다양한 수많은 데이터 소스에서 데이터를 읽고 처리할 수 있다는 것을 의미한다. 


**컴포넌트**

![img](https://velog.velcdn.com/images/busybean3/post/741382af-6746-4843-9002-7459c5d035dd/image.png)
위 그림에서 보듯,  4개의 컴포넌트는 다양한 워크로드를 위한 라이브러리로 스파크 SQL, 스파크 MLlib, 스파크 정형화 스트리밍, GraphX 등을 제공한다. API를 써서 스파크 애플리케이션을 만들면 스파크 코어 엔진이 적절한 DAG로 변환해 실행한다. 스파크 코어는 자바, R, 스칼라, SQL, 파이썬 중  어느 것으로 사용하더라도 실제 코드는 경량화된 바이트 코드로 변환되어 워커 노드의 JVM에서 실행된다.

- 스파크 SQL: RDBMS 테이블이나 구조화된 데이터의 파일 포맷(csv, json, 텍스트 등)에서 데이터를 읽어들일 수 있으며, 스파크에서 새롭게 영구적이거나 임시적인 테이블을 만들 수 있다. 또한 스파크 SQL API를 사용하여 sql 계통의 질의를 하고 데이터 프레임을 만들 수 있다.
- 스파크 MLlib: 데이터 안의 특성들을 추출하고 변형하고, 파이프라인을 구축하고 배포하는 동안 모델을 보존해주는 API들이 있으며, 그 외에도 일반적인 선형대수 연산을 지원한다. 
- 스파크 정형화 스트리밍: 빅데이터 개발자들은 다른 데이터 소스에서 들어오는 데이터들도 실시간으로 연결하고 반응하기 위해 정형화 스트리밍 모델이 필요하다. 스트림을 연속적으로 증가하는 테이블이자, 끝에 계속 새로운 레코드가 추가되는 것으로 본다. 
- GraphX: 그래프를 조작하고 그래프 병렬 연산을 수행하기 위한 라이브러리다. 분석, 연결 탐색 등의 표준적인 그래프 알고리즘 뿐만 아니라 페이지랭크, 연결 컴포넌트, 삼각 집계 등의 알고리즘도 포함하고 있다.


### 아파치 스카프의 분산 실행
이번에는 어떻게 스파크의 분산 아키텍처 위에서 모든 컴포넌트들이 같이 동작하고 서로 통신하는지, 어떻게 배포가 가능한지 알아보겠다.

하나의 스파크 애플리케이션은 스파크 클러스터의 병렬 작업들을 조율하는 하나의 드라이버 프로그램으로 이루어진다.
드라이버는 SparkSession 객체를 통해 클러스터의 분산 컴포넌트에 접근한다.

**스파크 드라이버**
스파크 드라이버는 SparkSession 객체를 초기화하는 책임을 가진 스파크 애플리케이션의 일부로써 많은 역할을 한다. 클러스터 매니저와 통신하며 스파크 이그제큐터들을 위해 필요한 자원을 요청하고 모든 스파크 작업을 DAG 연산 형태로 변환하고 스케줄링하며 각 실행 단위를 태스크로 나누어 스파크 이그제큐터들에게 분배한다. 

**SparkSession**
SparkSession은 모든 스파크 연산과 데이터에 대한 통합 연결 채널이다. 이 연결 채널은 스파크의 모든 기능을 한 군데에서 접근할 수 있는 시작점이 된다. 

**클러스터 매니저**
클러스터 매니저는 스파크 애플리케이션이 실행되는 클러스터에서 자원을 관리 및 할당하는 책임을 지닌다. 
내장 단독(standakine) 클러스터 매니저, 아파치 하둡 얀(YARN), 아파치 메소스(Mesos), 쿠버네티스(Kubernetes) 이렇게 총 4가지 클러스터 매니저가 있다.

**스파크 이그제큐터**
스파크 이그제큐터는 클러스터의 각 워커 노드에서 동작하며, 드라이버 프로그램과 통신하여 워커에서 태스크를 실행하는 역할을 한다. 대부분의 베포 모드에서 노드 당 하나의 이그제큐터만이 실행된다.

**배포 모드**
스파크의 매력적인 특징 중 하나는 스파크 어플리케이션이 여러 다른 환경에서 다른 설정으로도 돌아갈 수 있도록 다양한 배포 모드를 지원한다는 것이다. 
